\section{Study}\label{sec:study}

Our research study includes development of an operator development API that enables users to write their own operators and streaming applications easily. It aims to provide a simple processing paradigm, isolate user code and the streaming runtime, have a flexible operator life cycle management and make operator behavior visible to the streaming engine. With all these advantages obtained by the operator development API, streaming runtime will be able to pursue all optimization opportunities mentioned in Section~\ref{sec:execution-model}. 

Key element of our API is a very cohesive interface definition, as shown in Listing~\ref{code:operator-interface}, to be used for operator development. Operator developers only implement the computation logic to be invoked during execution and the life-cycle logic to be invoked while operator is being initialized or shut down. This approach frees them to deal with the burden of overall management of the streaming runtime.

Our operator development API gains its advantages from its simplicity. An operator is only responsible for performing its own logic without dealing with any aspect of the streaming runtime. It also makes its behavior visible to the streaming runtime so that it can decide on proper optimizations and apply them safely. In this context, our API forms a degree of isolation and loose coupling between user code and the streaming runtime. Not only this advantage saves the operator developer from a lot of burden, but also it gives a lot of freedom to the streaming runtime in terms of configurations, logical-to-physical mappings and performance optimizations.

\lstset{language=JAVA, caption="Operator Interface"}
\begin{lstlisting}[frame=single] 
public interface Operator
{
    SchedulingStrategy init ( InitializationContext context );
	
    InvocationResult process ( InvocationContext invocation );

    void shutdown ();
}
\end{lstlisting}
\label{code:operator-interface}

\subsection{Data Processing API}\label{sec:data-processing-api}

We define \textit{Tuple} as the unit of data in our system. It forms a data model as a collection of key-value pairs. Values can be any type while keys are typed as \textit{String}. It also contains various methods to manipulate its internal key-value pairs. Tuples are manipulated by operators and moved through the streams between operators.

We mimic functional programming paradigm to provide an API for tuple processing. In our API, we have a single processing method, \texttt{process()}, as displayed in Listing~\ref{code:operator-interface}. This method is responsible for implementation of operators' computation logic. Streaming engine invokes \texttt{process()} method of an operator with the tuples sent to it by other operators, along with all other runtime elements required to perform the computation. For instance, if an operator declares itself as a stateful operator, a key value store API is provided to the operator on \texttt{process()} invocations. 

Operators use implementations of \texttt{SchedulingStrategy} interface to specify when their \texttt{process()} method should be invoked. Currently, we are only focusing on invocations based on tuple availability in input queues of the operators. Therefore, operators specify how many tuples they need in each input queue to perform their computation. Once these requirements are met, streaming runtime is allowed to invoke the operator. An operator may have multiple input ports and it may also require different number of tuples for each one of its input ports. Streaming runtime will not invoke that operator until all of the specified tuple requirements are met. Additionally, operators also specify if they require an exact number of tuples for invocations or they can handle more tuples than required. For instance, an operator may specify that it requires exactly three tuples on its input queue for an invocation. Then, streaming runtime makes all invocations with exactly three tuples. On the other hand, if an operator specifies that it requires at least three tuples, streaming runtime can perform batching and invoke the operator with a high number of tuples. 

Operators may change their \texttt{SchedulingStrategy} between invocations. \texttt{SchedulingStrategy} returned within the \texttt{InvocationResult} is used for next invocation of the operator. Related to this, an unexpected invocation can be done for some cases. For instance, streaming runtime may detect that tuple requirements of an operator will be never satisfied. If that is the case, it invokes \texttt{process()} method of the operator and notifies it with a field in the \texttt{InvocationContext} class.

Lastly, result of computations is also represented with tuples which are returned from invocations of \texttt{process()} method. It is streaming runtime's responsibility to deliver these tuples to their targets.

\subsection{Operator Life Cycle Management}\label{sec:operator-lifecycle}

% life cycle methods, configurability, performing actions 
Operators may need to perform side-effecting tasks to manipulate tuples. For instance, an operator may initialize a TCP connection and produce tuples using the data received from it. Once the streaming application starts running, the operator may create the connection and initiate a custom protocol to receive data. Similarly, before the streaming application shuts down, it may need to finalize the protocol so that the other participant does not attempt to send new data. To do this, streaming runtime should notify the operators on certain life cycle events. Currently, \texttt{Operator} interface contains \texttt{init()} and \texttt{shutdown()} methods to support this functionality, as shown in Listing~\ref{code:operator-interface}. 

We also have operator configuration capabilities in our API to support development of generic, reusable operators. Configuration parameters of an operator can be decided at \textit{composition time} and passed to the streaming application while building the operator graph. Operators can receive their configuration values in \texttt{OperatorConfig} object which is accessed via \texttt{InitializationContext} object provided in \texttt{init()} method. For instance, a generic \texttt{Mapper} operator can map each input tuple to an output tuple by applying the \texttt{map} function received during initialization.

\subsection{Modeling the Operator Behavior}\label{sec:operator-behavior}

In order to provide safe and profitable optimizations, visibility of operator behavior is one of crucial points for the streaming runtime. Our operator development API contains two annotations, \texttt{OperatorSpec}, \texttt{OperatorSchema}, to elaborate operator behavior. \texttt{OperatorSpec} annotation is used for specifying type (i.e. whether operator maintains local state or not) and arity (i.e. input and output port counts) of the operators while \texttt{OperatorSchema} is used for specifying data model (i.e. list of fields guaranteed to exist in input and output tuples) of the operators. API is flexible in such a way that it allows users to model the behavior on both \textit{design time} (i.e., while developing the operator) or \textit{composition time} (i.e., while adding operator to an operator graph). 

We have three operator types to classify operators in terms of managing local state for tuple processing: \textit{stateless}, \textit{stateful} and \textit{partitioned stateful}. First operator type is \textit{stateless} operators which process each tuple on its own without depending to any other tuple or mutable shared state. Second operator type is \textit{stateful} operators which maintain a local state which is shared between processing of multiple tuples. An operator that counts number of tuples it receives is stateful. A stateful operator is not amenable to replication since it requires a single copy of its local state for correctness. The last one is \textit{partitioned stateful} operators which group tuples into partitions based on partition field configuration and maintain a separate instance of local state for each partition. Tuples that fall into the same partition are processed using same local state instance. 

\texttt{OperatorSpec} annotation is also used to specify port counts of operators. Stateless operators can have at most one input port. Partitioned stateful and stateful operators can have any number of input and output ports. Users can specify input and output port counts of their operators on both design time and composition time. 

Lastly, we declare data model of an operator using \texttt{OperatorSchema} annotation. It contains separate data models for each input and output port, which are called \textit{port schemas}. A port schema declares a list of field name, value type pairs of interest. To create a stream between two operators, their connected ports must have \textit{compatible} schemas, which means port schema of the source operator should satisfy all the fields expected by port of the target operator. Users can annotate whether a port schema is completely declared on design time or it can be extended in composition time. For instance, a generic \textt{Mapper} operator, which maps every input tuple to a new tuple using the provided \texttt{mapper} function can be specified with an empty design time schema. Once it is connected o any operator via a stream, its corresponding port schema can be specified based on the port schema at the other end of the stream.




\subsection{Building the Operator Graph}\label{sec:operator-graph}