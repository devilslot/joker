\section{Study}\label{sec:study}

A streaming application can be represented as a directed graph where vertices are operators and edges are the streams connected via operators' ports. It can be defined with a visual editor, a stream processing library or a domain specific language specially designed for stream processing. We prefer to develop a library in Java to enable users to write their own streaming applications. Our library contains a simple and powerful operator development API. It aims to provide a simple processing paradigm, isolation between user code and the streaming runtime, flexible operator life cycle management and visibility of operator behavior. 

Key element of our API is a very cohesive interface definition, as shown in Listing~\ref{code:operator-interface}, to be used for operator development. Operator developers only implement the computation logic to be invoked during execution and the life-cycle logic to be invoked while operator is being initialized or shut down. This approach frees them to deal with the burden of overall management of the streaming runtime.

\texttt{Operator} interface is accompanied with two annotations which are used to make operator behavior visible to the streaming runtime. These annotations are used for specifying type (i.e. whether operator maintains local state or not), arity (i.e. input and output port counts) and data model (i.e. list of fields guaranteed to exist in the data) of an operator. Our API has the flexibility of modeling operator behavior on both design time (i.e., while developing the operator) or composition time (i.e., while adding operator to an operator graph). For instance, a user can develop a barrier operator which produces an output only when it receives data from all of its input ports and he can decide on the number of input ports while adding this operator to the streaming application. 

Our operator development API gets its power from its simplicity. An operator is only responsible for performing its own computation and life cycle logic without dealing with any aspect of the streaming runtime. It also makes its behavior visible to the streaming runtime so that it can decide on proper optimizations and apply them safely. In this context, API forms a degree of isolation and loose coupling between user code and the streaming runtime. Not only this advantage saves the operator developer from a lot of burden, but also it gives a lot of freedom to the streaming runtime.

\lstset{language=JAVA, caption="Operator Interface"}
\begin{lstlisting}[frame=single] 
public interface Operator
{
    SchedulingStrategy init ( InitializationContext context );
	
    InvocationResult process ( InvocationContext invocation );

    void shutdown ();
}
\end{lstlisting}
\label{code:operator-interface}

\subsection{Data Processing API}\label{sec:data-processing-api}

We define \textit{Tuple} as the unit of data in our system. It defines the data model as a collection of key-value pairs. Values can be any type while keys are typed as \textit{String}. It also contains various methods to manipulate its internal key-value pairs. Tuples are manipulated by operators and moved through the streams between operators.

We mimic functional programming paradigm to provide an API for tuple processing. In our API, we have a single processing method, \texttt{process()}, as displayed in Listing~\ref{code:operator-interface}. This method is responsible for implementation of operators' computation logic. Streaming engine invokes \texttt{process()} method of an operator with the tuples sent to it by other operators, along with all other runtime elements required to perform the computation. For instance, if an operator declares itself as a stateful operator, a key value store API is provided to the operator on \texttt{process()} invocations. 

Operators use implementations of \texttt{SchedulingStrategy} interface to specify when their \texttt{process()} method should be invoked. Currently, we are only focusing on invocations based on tuple availability in input queues of the operators. Therefore, operators specify how many tuples they need in each input queue to perform their computation. Once these requirements are met, streaming runtime is allowed to invoke the operator. An operator may have multiple input ports and it may also require different number of tuples for each one of its input ports. Streaming runtime will not invoke that operator until all of the specified tuple requirements are met. Additionally, operators also specify if they require an exact number of tuples for invocations or they can handle more tuples than required. For instance, an operator may specify that it requires exactly three tuples on its input queue for an invocation. Then, streaming runtime makes all invocations with exactly three tuples. On the other hand, if an operator specifies that it requires at least three tuples, streaming runtime can perform batching and invoke the operator with a high number of tuples. 

Operators may change their \texttt{SchedulingStrategy} between invocations. \texttt{SchedulingStrategy} returned within the \texttt{InvocationResult} is used for next invocation of the operator. Related to this, an unexpected invocation can be done for some cases. For instance, streaming runtime may detect that tuple requirements of an operator will be never satisfied. If that is the case, it invokes \texttt{process()} method of the operator and notifies it with a field in the \texttt{InvocationContext} class.

Lastly, result of computations is also represented with tuples which are returned from invocations of \texttt{process()} method. It is streaming runtime's responsibility to deliver these tuples to their targets.

\subsection{Operator Life Cycle Management}\label{sec:operator-lifecycle}

% life cycle methods, configurability, performing actions 

\subsection{Modeling the Operator Behavior}\label{sec:operator-behavior}